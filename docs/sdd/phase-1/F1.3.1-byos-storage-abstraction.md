# F1.3.1: BYOS Storage Abstraction Layer

**Version:** 1.0.0
**Priority:** P0 (Critical)
**Effort:** High (5-7 days)
**Dependencies:** F1.1.1, F1.1.2

---

## Overview

Implement the Bring Your Own Storage (BYOS) abstraction layer - Learning Hall's key differentiator. This allows creators to connect their own S3-compatible storage (AWS S3, Cloudflare R2, Google Cloud Storage, Backblaze B2, MinIO) instead of relying on platform storage.

---

## Objectives

1. Create unified storage provider interface
2. Implement credential encryption/decryption
3. Build storage configuration UI
4. Support multiple S3-compatible providers
5. Implement signed URL generation
6. Add storage health checking
7. Create fallback to platform storage

---

## Technical Specification

### Storage Provider Interface

```typescript
// src/lib/storage/types.ts
export interface StorageProvider {
  readonly name: string;
  readonly provider: StorageProviderType;

  /**
   * Upload a file to storage
   */
  upload(params: UploadParams): Promise<UploadResult>;

  /**
   * Download a file from storage
   */
  download(key: string): Promise<Buffer>;

  /**
   * Delete a file from storage
   */
  delete(key: string): Promise<void>;

  /**
   * Delete multiple files
   */
  deleteMany(keys: string[]): Promise<void>;

  /**
   * Get a signed URL for temporary access
   */
  getSignedUrl(key: string, options?: SignedUrlOptions): Promise<string>;

  /**
   * Get a signed URL for uploads
   */
  getSignedUploadUrl(key: string, options?: SignedUploadUrlOptions): Promise<SignedUploadResult>;

  /**
   * List files with a given prefix
   */
  list(prefix: string, options?: ListOptions): Promise<ListResult>;

  /**
   * Check if a file exists
   */
  exists(key: string): Promise<boolean>;

  /**
   * Get file metadata
   */
  getMetadata(key: string): Promise<FileMetadata>;

  /**
   * Test connection to storage
   */
  testConnection(): Promise<ConnectionTestResult>;
}

export type StorageProviderType = 's3' | 'r2' | 'gcs' | 'b2' | 'minio' | 'local';

export interface StorageConfig {
  id: string;
  tenantId: string;
  provider: StorageProviderType;
  bucket: string;
  region?: string;
  endpoint?: string;
  credentials: {
    accessKeyId: string;
    secretAccessKey: string;
  };
  isActive: boolean;
  createdAt: Date;
  updatedAt: Date;
}

export interface UploadParams {
  key: string;
  body: Buffer | ReadableStream;
  contentType?: string;
  metadata?: Record<string, string>;
  acl?: 'private' | 'public-read';
}

export interface UploadResult {
  key: string;
  url: string;
  etag?: string;
  size: number;
}

export interface SignedUrlOptions {
  expiresIn?: number; // seconds, default 3600
  responseContentType?: string;
  responseContentDisposition?: string;
}

export interface SignedUploadUrlOptions {
  expiresIn?: number;
  contentType?: string;
  maxSize?: number; // bytes
}

export interface SignedUploadResult {
  url: string;
  fields?: Record<string, string>;
  key: string;
}

export interface ListOptions {
  maxKeys?: number;
  continuationToken?: string;
}

export interface ListResult {
  files: FileInfo[];
  continuationToken?: string;
  isTruncated: boolean;
}

export interface FileInfo {
  key: string;
  size: number;
  lastModified: Date;
  etag?: string;
}

export interface FileMetadata {
  key: string;
  size: number;
  contentType?: string;
  lastModified: Date;
  metadata?: Record<string, string>;
}

export interface ConnectionTestResult {
  success: boolean;
  error?: string;
  latencyMs?: number;
}
```

### S3-Compatible Provider Implementation

```typescript
// src/lib/storage/providers/s3-provider.ts
import {
  S3Client,
  PutObjectCommand,
  GetObjectCommand,
  DeleteObjectCommand,
  DeleteObjectsCommand,
  ListObjectsV2Command,
  HeadObjectCommand,
} from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { createPresignedPost } from '@aws-sdk/s3-presigned-post';
import type {
  StorageProvider,
  StorageConfig,
  UploadParams,
  UploadResult,
  SignedUrlOptions,
  SignedUploadUrlOptions,
  SignedUploadResult,
  ListOptions,
  ListResult,
  FileMetadata,
  ConnectionTestResult,
  StorageProviderType,
} from '../types';

const PROVIDER_ENDPOINTS: Record<StorageProviderType, string | undefined> = {
  s3: undefined, // Uses default AWS endpoint
  r2: undefined, // Set dynamically with accountId
  gcs: 'https://storage.googleapis.com',
  b2: 'https://s3.us-west-001.backblazeb2.com',
  minio: undefined, // Set from config
  local: undefined,
};

export class S3CompatibleProvider implements StorageProvider {
  readonly name: string;
  readonly provider: StorageProviderType;
  private client: S3Client;
  private bucket: string;

  constructor(config: StorageConfig) {
    this.name = `${config.provider}:${config.bucket}`;
    this.provider = config.provider;
    this.bucket = config.bucket;

    const endpoint = this.getEndpoint(config);

    this.client = new S3Client({
      region: config.region || 'auto',
      endpoint,
      credentials: {
        accessKeyId: config.credentials.accessKeyId,
        secretAccessKey: config.credentials.secretAccessKey,
      },
      forcePathStyle: ['minio', 'local'].includes(config.provider),
    });
  }

  private getEndpoint(config: StorageConfig): string | undefined {
    if (config.endpoint) return config.endpoint;

    switch (config.provider) {
      case 'r2':
        // R2 endpoint requires account ID extracted from access key or config
        return config.endpoint;
      case 'gcs':
        return PROVIDER_ENDPOINTS.gcs;
      case 'b2':
        return PROVIDER_ENDPOINTS.b2;
      default:
        return undefined;
    }
  }

  async upload(params: UploadParams): Promise<UploadResult> {
    const command = new PutObjectCommand({
      Bucket: this.bucket,
      Key: params.key,
      Body: params.body,
      ContentType: params.contentType,
      Metadata: params.metadata,
      ACL: params.acl,
    });

    const result = await this.client.send(command);

    return {
      key: params.key,
      url: `https://${this.bucket}.s3.amazonaws.com/${params.key}`,
      etag: result.ETag,
      size: Buffer.isBuffer(params.body) ? params.body.length : 0,
    };
  }

  async download(key: string): Promise<Buffer> {
    const command = new GetObjectCommand({
      Bucket: this.bucket,
      Key: key,
    });

    const result = await this.client.send(command);

    if (!result.Body) {
      throw new Error(`File not found: ${key}`);
    }

    // Convert stream to buffer
    const chunks: Uint8Array[] = [];
    for await (const chunk of result.Body as AsyncIterable<Uint8Array>) {
      chunks.push(chunk);
    }
    return Buffer.concat(chunks);
  }

  async delete(key: string): Promise<void> {
    const command = new DeleteObjectCommand({
      Bucket: this.bucket,
      Key: key,
    });

    await this.client.send(command);
  }

  async deleteMany(keys: string[]): Promise<void> {
    if (keys.length === 0) return;

    const command = new DeleteObjectsCommand({
      Bucket: this.bucket,
      Delete: {
        Objects: keys.map((key) => ({ Key: key })),
      },
    });

    await this.client.send(command);
  }

  async getSignedUrl(key: string, options: SignedUrlOptions = {}): Promise<string> {
    const command = new GetObjectCommand({
      Bucket: this.bucket,
      Key: key,
      ResponseContentType: options.responseContentType,
      ResponseContentDisposition: options.responseContentDisposition,
    });

    return getSignedUrl(this.client, command, {
      expiresIn: options.expiresIn || 3600,
    });
  }

  async getSignedUploadUrl(
    key: string,
    options: SignedUploadUrlOptions = {}
  ): Promise<SignedUploadResult> {
    const { url, fields } = await createPresignedPost(this.client, {
      Bucket: this.bucket,
      Key: key,
      Conditions: [
        ['content-length-range', 0, options.maxSize || 100 * 1024 * 1024], // 100MB default
        ...(options.contentType ? [['eq', '$Content-Type', options.contentType] as const] : []),
      ],
      Expires: options.expiresIn || 3600,
    });

    return { url, fields, key };
  }

  async list(prefix: string, options: ListOptions = {}): Promise<ListResult> {
    const command = new ListObjectsV2Command({
      Bucket: this.bucket,
      Prefix: prefix,
      MaxKeys: options.maxKeys || 1000,
      ContinuationToken: options.continuationToken,
    });

    const result = await this.client.send(command);

    return {
      files: (result.Contents || []).map((obj) => ({
        key: obj.Key!,
        size: obj.Size!,
        lastModified: obj.LastModified!,
        etag: obj.ETag,
      })),
      continuationToken: result.NextContinuationToken,
      isTruncated: result.IsTruncated || false,
    };
  }

  async exists(key: string): Promise<boolean> {
    try {
      await this.getMetadata(key);
      return true;
    } catch {
      return false;
    }
  }

  async getMetadata(key: string): Promise<FileMetadata> {
    const command = new HeadObjectCommand({
      Bucket: this.bucket,
      Key: key,
    });

    const result = await this.client.send(command);

    return {
      key,
      size: result.ContentLength!,
      contentType: result.ContentType,
      lastModified: result.LastModified!,
      metadata: result.Metadata,
    };
  }

  async testConnection(): Promise<ConnectionTestResult> {
    const start = Date.now();

    try {
      // Try to list a single object to test connection
      await this.list('', { maxKeys: 1 });

      return {
        success: true,
        latencyMs: Date.now() - start,
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        latencyMs: Date.now() - start,
      };
    }
  }
}
```

### Credential Encryption

```typescript
// src/lib/storage/encryption.ts
import { createCipheriv, createDecipheriv, randomBytes, scryptSync } from 'crypto';

const ALGORITHM = 'aes-256-gcm';
const IV_LENGTH = 16;
const AUTH_TAG_LENGTH = 16;
const SALT_LENGTH = 32;

function deriveKey(password: string, salt: Buffer): Buffer {
  return scryptSync(password, salt, 32);
}

export function encryptCredentials(
  credentials: object,
  masterKey: string = process.env.STORAGE_ENCRYPTION_KEY!
): string {
  const salt = randomBytes(SALT_LENGTH);
  const key = deriveKey(masterKey, salt);
  const iv = randomBytes(IV_LENGTH);

  const cipher = createCipheriv(ALGORITHM, key, iv);

  const plaintext = JSON.stringify(credentials);
  let encrypted = cipher.update(plaintext, 'utf8', 'hex');
  encrypted += cipher.final('hex');

  const authTag = cipher.getAuthTag();

  // Format: salt:iv:authTag:encrypted
  return [
    salt.toString('hex'),
    iv.toString('hex'),
    authTag.toString('hex'),
    encrypted,
  ].join(':');
}

export function decryptCredentials(
  encryptedString: string,
  masterKey: string = process.env.STORAGE_ENCRYPTION_KEY!
): object {
  const [saltHex, ivHex, authTagHex, encrypted] = encryptedString.split(':');

  const salt = Buffer.from(saltHex, 'hex');
  const iv = Buffer.from(ivHex, 'hex');
  const authTag = Buffer.from(authTagHex, 'hex');
  const key = deriveKey(masterKey, salt);

  const decipher = createDecipheriv(ALGORITHM, key, iv);
  decipher.setAuthTag(authTag);

  let decrypted = decipher.update(encrypted, 'hex', 'utf8');
  decrypted += decipher.final('utf8');

  return JSON.parse(decrypted);
}
```

### Storage Service Factory

```typescript
// src/lib/storage/storage-service.ts
import { getPayloadClient } from '@/lib/payload';
import { S3CompatibleProvider } from './providers/s3-provider';
import { LocalProvider } from './providers/local-provider';
import { decryptCredentials } from './encryption';
import type { StorageProvider, StorageConfig } from './types';

const providerCache = new Map<string, StorageProvider>();

export async function getStorageProvider(tenantId: string): Promise<StorageProvider> {
  // Check cache first
  const cached = providerCache.get(tenantId);
  if (cached) return cached;

  const payload = await getPayloadClient();

  // Fetch tenant's storage configuration
  const { docs } = await payload.find({
    collection: 'storage-configs',
    where: {
      tenant: { equals: tenantId },
      isActive: { equals: true },
    },
    limit: 1,
  });

  if (docs.length === 0) {
    // Fall back to platform default storage
    return getDefaultProvider();
  }

  const config = docs[0];

  // Decrypt credentials
  const credentials = decryptCredentials(config.credentialsEncrypted) as {
    accessKeyId: string;
    secretAccessKey: string;
  };

  const storageConfig: StorageConfig = {
    id: config.id,
    tenantId,
    provider: config.provider,
    bucket: config.bucket,
    region: config.region,
    endpoint: config.endpoint,
    credentials,
    isActive: config.isActive,
    createdAt: new Date(config.createdAt),
    updatedAt: new Date(config.updatedAt),
  };

  let provider: StorageProvider;

  if (config.provider === 'local') {
    provider = new LocalProvider(storageConfig);
  } else {
    provider = new S3CompatibleProvider(storageConfig);
  }

  // Cache the provider
  providerCache.set(tenantId, provider);

  return provider;
}

function getDefaultProvider(): StorageProvider {
  // Use environment variables for default platform storage
  const config: StorageConfig = {
    id: 'default',
    tenantId: 'platform',
    provider: process.env.DEFAULT_STORAGE_PROVIDER as any || 'r2',
    bucket: process.env.DEFAULT_STORAGE_BUCKET!,
    region: process.env.DEFAULT_STORAGE_REGION,
    endpoint: process.env.DEFAULT_STORAGE_ENDPOINT,
    credentials: {
      accessKeyId: process.env.DEFAULT_STORAGE_ACCESS_KEY!,
      secretAccessKey: process.env.DEFAULT_STORAGE_SECRET_KEY!,
    },
    isActive: true,
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  return new S3CompatibleProvider(config);
}

export function clearProviderCache(tenantId?: string): void {
  if (tenantId) {
    providerCache.delete(tenantId);
  } else {
    providerCache.clear();
  }
}
```

### Storage Configuration Collection

```typescript
// src/collections/StorageConfigs.ts
import type { CollectionConfig } from 'payload';
import { encryptCredentials } from '@/lib/storage/encryption';

export const StorageConfigs: CollectionConfig = {
  slug: 'storage-configs',
  admin: {
    useAsTitle: 'bucket',
    group: 'Settings',
  },
  access: {
    read: ({ req }) => {
      if (req.user?.role === 'admin') return true;
      return { tenant: { equals: req.user?.tenant } };
    },
    create: ({ req }) => ['admin', 'instructor'].includes(req.user?.role || ''),
    update: ({ req }) => {
      if (req.user?.role === 'admin') return true;
      return { tenant: { equals: req.user?.tenant } };
    },
    delete: ({ req }) => req.user?.role === 'admin',
  },
  hooks: {
    beforeChange: [
      async ({ data, operation }) => {
        // Encrypt credentials before saving
        if (data.accessKeyId && data.secretAccessKey) {
          data.credentialsEncrypted = encryptCredentials({
            accessKeyId: data.accessKeyId,
            secretAccessKey: data.secretAccessKey,
          });
          // Remove plaintext credentials
          delete data.accessKeyId;
          delete data.secretAccessKey;
        }
        return data;
      },
    ],
  },
  fields: [
    {
      name: 'tenant',
      type: 'relationship',
      relationTo: 'tenants',
      required: true,
      admin: {
        position: 'sidebar',
      },
    },
    {
      name: 'provider',
      type: 'select',
      required: true,
      options: [
        { label: 'AWS S3', value: 's3' },
        { label: 'Cloudflare R2', value: 'r2' },
        { label: 'Google Cloud Storage', value: 'gcs' },
        { label: 'Backblaze B2', value: 'b2' },
        { label: 'MinIO', value: 'minio' },
        { label: 'Local Filesystem', value: 'local' },
      ],
    },
    {
      name: 'bucket',
      type: 'text',
      required: true,
    },
    {
      name: 'region',
      type: 'text',
      admin: {
        condition: (data) => ['s3', 'gcs'].includes(data.provider),
      },
    },
    {
      name: 'endpoint',
      type: 'text',
      admin: {
        description: 'Custom endpoint URL (required for R2, MinIO)',
        condition: (data) => ['r2', 'minio', 'b2'].includes(data.provider),
      },
    },
    {
      name: 'accessKeyId',
      type: 'text',
      admin: {
        description: 'Access Key ID (will be encrypted)',
      },
    },
    {
      name: 'secretAccessKey',
      type: 'text',
      admin: {
        description: 'Secret Access Key (will be encrypted)',
      },
    },
    {
      name: 'credentialsEncrypted',
      type: 'text',
      hidden: true,
      admin: {
        disabled: true,
      },
    },
    {
      name: 'isActive',
      type: 'checkbox',
      defaultValue: true,
      admin: {
        position: 'sidebar',
      },
    },
  ],
  timestamps: true,
};
```

---

## Acceptance Criteria

### Functional

- [ ] Storage provider interface defined with all operations
- [ ] AWS S3 provider works with valid credentials
- [ ] Cloudflare R2 provider works with valid credentials
- [ ] Credentials encrypted before database storage
- [ ] Credentials decrypted at runtime only
- [ ] Signed URLs generated with configurable expiry
- [ ] Presigned upload URLs work for direct browser uploads
- [ ] Storage configuration UI in dashboard
- [ ] Connection test validates credentials before saving
- [ ] Fallback to platform storage when no config exists

### Non-Functional

- [ ] Credential encryption uses AES-256-GCM
- [ ] Provider instances cached to avoid repeated decryption
- [ ] Signed URLs default to 1 hour expiry
- [ ] Upload URLs default to 100MB max file size
- [ ] No plaintext credentials in logs or error messages

---

## Security Considerations

1. **Never log credentials** - Use sanitized error messages
2. **Encrypt at rest** - All credentials encrypted with AES-256-GCM
3. **Decrypt on demand** - Credentials decrypted only when needed
4. **Rotate keys** - Support for credential rotation
5. **Validate on save** - Test connection before saving config
6. **Minimal permissions** - Recommend least-privilege IAM policies

### Recommended IAM Policy for S3

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::your-bucket",
        "arn:aws:s3:::your-bucket/*"
      ]
    }
  ]
}
```

---

**Document Version:** 1.0.0
**Last Updated:** January 2026
